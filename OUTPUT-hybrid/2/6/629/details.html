<html><h3>54fed17211d0b077579fba58e93075aee9312668,texar/modules/decoders/transformer_decoders.py,TransformerDecoder,__init__,#TransformerDecoder#Any#Any#Any#,85
</h3><img src='848877.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            &#47&#47 Make the output layer
            if is_callable(output_layer):
                self._output_layer = output_layer
            elif <a id="change">tf</a>.contrib.framework.is_tensor(output_layer):
                self._vocab_size = shape_list(output_layer)[1]
                self._output_layer = self._make_output_layer_from_tensor(
                    output_layer)
            elif output_layer is None:
                <a id="change">if self._vocab_size is None:
                    raise ValueError(
                        "Either `output_layer` or `vocab_size` must be provided"
                        " Set `output_layer=tf.identity` if no output layer is "
                        "wanted.")
               </a> with tf.variable_scope(self.variable_scope):
                    self._output_layer = tf.layers.Dense(
                        units=self._vocab_size,
                        use_bias=self._hparams.output_layer_bias)
            else:
                <a id="change">raise ValueError(
                    "output_layer should be tensor or callable layer or None."
                    "Unsupported type:", type(output_layer)
                )</a>
            self.multihead_attentions = {
                &quotself_att&quot: [],
                &quotencdec_att&quot: []
            }</code></pre><h3>After Change</h3><pre><code class='java'>
                    layers.get_initializer(self._hparams.initializer))

            &#47&#47 Make the output layer
            <a id="change">self</a>._output_layer, self._vocab_size = _make_output_layer(
                output_layer, vocab_size, self._hparams.output_layer_bias,
                self.variable_scope)
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/asyml/texar/commit/54fed17211d0b077579fba58e93075aee9312668#diff-503bcdf232acbf72c937e1f5dc030a70d6b8090987f9b11e3e25650f962b56f4L85' target='_blank'>Link</a></div><div id='project'> Project Name: asyml/texar</div><div id='commit'> Commit Name: 54fed17211d0b077579fba58e93075aee9312668</div><div id='time'> Time: </div><div id='author'> Author: null</div><div id='file'> File Name: texar/modules/decoders/transformer_decoders.py</div><div id='class'> Class Name: TransformerDecoder</div><div id='method'> Method Name: __init__</div><BR><BR><div id='link'><a href='https://github.com/asyml/texar/commit/54fed17211d0b077579fba58e93075aee9312668#diff-197e32a650b5585b4875dd4c5eaeeedc069033839bad0c138b1c1728493c2938L56' target='_blank'>Link</a></div><div id='project'> Project Name: asyml/texar</div><div id='commit'> Commit Name: 54fed17211d0b077579fba58e93075aee9312668</div><div id='time'> Time: </div><div id='author'> Author: null</div><div id='file'> File Name: texar/modules/decoders/rnn_decoder_base.py</div><div id='class'> Class Name: RNNDecoderBase</div><div id='method'> Method Name: __init__</div><BR><BR><div id='link'><a href='https://github.com/tensorflow/agents/commit/1bef8a0cb502401e33f8572897d981ef81a1a829#diff-c9a02749f6ad063e038acf8968ce2f418ddf3cc10aba5651b54aabbe940724adL248' target='_blank'>Link</a></div><div id='project'> Project Name: tensorflow/agents</div><div id='commit'> Commit Name: 1bef8a0cb502401e33f8572897d981ef81a1a829</div><div id='time'> Time: </div><div id='author'> Author: null</div><div id='file'> File Name: tf_agents/bandits/policies/neural_linucb_policy.py</div><div id='class'> Class Name: NeuralLinUCBPolicy</div><div id='method'> Method Name: _action</div><BR>