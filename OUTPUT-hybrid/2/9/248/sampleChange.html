<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    else :
        inputImgAfterDropout = inputTrain
        inputImgAfterDropoutInference = inputInference
        <a id="change">inputImgAfterDropoutTesting = inputTesting</a>
    <a id="change">return (inputImgAfterDropout, inputImgAfterDropoutInference, inputImgAfterDropoutTesting)</a>


def applyBn(rollingAverageForBatchNormalizationOverThatManyBatches, inputTrain, inputVal, inputTest, inputShapeTrain) :
    numberOfChannels = inputShapeTrain[1]</code></pre><h3>After Change</h3><pre><code class='java'>
    if dropoutRate &gt; 0.001 : &#47&#47Below 0.001 I take it as if there is no dropout at all. (To avoid float problems with == 0.0. Although my tries show it actually works fine.)
        keep_prob = (1-dropoutRate)
        
        <a id="change">random_tensor = keep_prob</a>
        <a id="change">random_tensor += tf.random_uniform(shape=inputTrainShape, minval=0., maxval=1., seed=rng.randint(999999), dtype="float32")</a>
        &#47&#47 0. if [keep_prob, 1.0) and 1. if [1.0, 1.0 + keep_prob)
        dropoutMask = tf.floor(random_tensor)
    
        &#47&#47 tf.nn.dropout(x, keep_prob) scales kept values UP, so that at inference you dont need to scale then. 
        inputImgAfterDropoutTrain = inputTrain * dropoutMask
        inputImgAfterDropoutVal = inputVal * keep_prob
        inputImgAfterDropoutTest = <a id="change">inputTest * keep_prob</a>
    else :
        inputImgAfterDropoutTrain = inputTrain
        <a id="change">inputImgAfterDropoutVal = inputVal</a>
        inputImgAfterDropoutTest = inputTest
    <a id="change">return (inputImgAfterDropoutTrain, inputImgAfterDropoutVal, inputImgAfterDropoutTest)</a>


def applyBn(rollingAverageForBatchNormalizationOverThatManyBatches, inputTrain, inputVal, inputTest, inputShapeTrain) :
    numOfChanns = inputShapeTrain[1]</code></pre>